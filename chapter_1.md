## 第一章 统计学习与监督学习概论

**1.1 统计学习**

- 统计学习的数据假设

	独立同分布
    
- 统计学习的基本方法

	- 基于先验知识构建含参数的统计概率模型（假设空间——学习的映射范围）
	- 基于某种评价准则采用最优化算法优化模型（策略、算法）

**1.2 统计学习基本概念**

- 监督学习

	- 输入和输出是定义在输入空间和输出空间的**随机变量**的取值
	- 输入空间 - 特征空间 - 输出空间
	- 模型往往更有效学习到特征空间到输出空间的映射

	- 变量标记
	
    	- 随机变量标记
    		- 输入随机变量
    			$$X$$
        	- 输出随机变量
        		$$Y$$
        	- 输入随机变量X的一个具体实例
        	
            	$$x = (x^{(1)}, x^{(2)},···,x^{(n)})^T$$
        
                - $x^{(i)}$表示$x$的第$i$个特征
                - $x_i$表示多个输入变量第$i$个变量（第$i$个样本特征）
            - 数据集表示

				$$T = {(x_1,y_1), (x_2,y_2),···(x_N,y_N)}$$
                
                - $y_i$表示多个输出变量第$i$个变量（第$i$个样本输出）
            
            	- $(x_i,y_i)$ 服从联合概率分布$P(X=x_i,Y=y_i)$,而$P(X=x_i,Y=y_i)$是未知的
           
          - 假设空间表达

			$$P(y|x) 或 y=f(x)$$
            
- 重要的学习观点

	- 全概率公式

		$$P(B) = \sum_{i=1}^{n}P(A_i)P(B|A_i)$$

	- 贝叶斯学习

		- 贝叶斯后验概率公式

		 $${P}(\theta | D)=\frac{P(\theta) P(D | \theta)}{P(D)}$$
         
         - $P(\theta)$为先验概率，表示预先假设的参数$\theta$服从的分布（**贝叶斯学派的重要观点**）
         - $P(D)$为数据分布，往往未知，否则即可根据$P(D)$生成数据
         - $P(D | \theta)$表示似然，即在给定参数$\theta$下的数据分布

		- 贝叶斯学习的意义

			- 取后验概率最大，估计整个后验概率  $P(\theta|D)$
			- 进行预测时，计算数据对后验概率分布的期望值 
				$$P(x | D)=\sum_{\theta} P(x | \theta, D) P(\theta | D)$$
                $x$ 是新样本。
                
                - $P(x | D)$指的是在给定已知样本数据下，预测新数据所使用的分布。因此，这个分布是关于数据，而非参数的分布。
                - $\sum_{\theta} P(x | \theta, D) P(\theta | D)$ 实际上是关于$\theta$的全概率公式，直观理解是在已知数据$D$下，估计的所有$\theta$下，$x$的发生概率
                -  $P(x | \theta, D)$的理解：$P(x | (\theta, D))$，在$\theta$和$D$已知的条件下
		- 贝叶斯的积分计算是**难点**

	- 最大似然估计
		
        $$\hat {\theta} = \arg max _{\theta} P(D | \theta)$$
        
        - 预先假设含有未定参数$\theta$的似然分布，未定参数$\theta$不是个随机变量（频率派观点）
        - 通过在已知数据$D$的$\theta$最大似然估计量

	- 最大似然估计和最大后验概率估计的联系

		假设先验分布是均匀分布，取后验概率最大，即可从贝叶斯估计得到最大似然估计
        
        由于$\theta$先验分布为均匀分布，则$P(\theta)$为常数，则
        $$\max P(\theta | D) = \max P(D | \theta)$$

	- 概率图模型

		将复杂的概率模型采用最基本的加法规则和乘法规则进行概率推理
        
        $$加法规则：P(x) = \sum_{y}P(x,y)$$
        $$乘法规则：P(x,y) = P(x)P(y|x)$$
        
  - 核方法
	
    一些线性模型的学习方法依赖于**相似度**计算，准确的讲是**向量内积**计算。有时在输入空间线性不可分，通过核方法，显式的定义从**输入空间（低维）到特征空间（高维）的映射**，实现线性可分，也就实现了线性模型到非线性模型的扩展。
      
**1.3 统计学习方法三要素**

- 概述

	方法 = 模型 + 策略 + 算法
    
- 模型（假设空间）

	- 决策函数族

		$$
\mathcal{F}=\left\{f | Y=f_{\theta}(X), \theta \in \mathbf{R}^{n}\right\}$$

	- 体检概率族

        $$\mathcal{F}=\left\{P\left|P_{\theta}(Y | X), \theta \in \mathbf{R}^{n}\right\}\right.$$
        
    - 性质

		- 假设空间中的模型一般是无穷多个
		- 统计学习的目的是**学习到最优$\theta$的决策函数**

- 策略（损失函数）

	- 损失函数与风险函数的概念

		- 损失函数度量模型**一次**预测的好坏
		- 风险函数度量**平均**意义下的模型预测的好坏

	- 常用的损失函数：

        1. 0-1 损失函数。   $L(Y, f(X))=\left\{\begin{array}{ll}{1,} & {Y \neq f(X)} \\ {0,} & {Y=f(X)}\end{array}\right.$
        
        2. 平方损失函数。  $L(Y, f(X))=(Y-f(X))^{2}$

        3. 绝对损失函数。 $L(Y, f(X))=|Y-f(X)|$
      
        4. 对数损失函数。 $L(Y, P(Y | X))=-\log P(Y | X)$

	- 从损失函数到风险函数

		- 期望损失

		$$\begin{aligned} R_{\mathrm{ exp }}(f) &=E_{P}[L(Y, f(X))] \\ &=\int_{\mathcal{X} \times \mathcal{Y}} L(y, f(x)) P(x, y) \mathrm{d} x \mathrm{d} y \end{aligned}
$$
			我们希望期望损失越小越好，但是联合概率分布 $P(X,Y)$未知，无法直接优化这个期望损失，因此使用训练数据集$D$上的**平均损失近似为期望损失**，称为经验损失
            
      - 经验损失

		$$R_{\mathrm{emp}}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)
$$

		依据大数定律，当$|D|$很大时，经验损失逼近期望损失。
        
  - 经验风险最小化和结构风险最小化

	通常数据样本有限，经验损失与期望损失偏差有些大，于是就要对经验风险进行矫正

	- 经验风险最小化（ERM）

		给定假设空间、损失函数和训练集的条件下，经验风险函数式是确定的，**经验风险最小就是模型最优**，于是就转换成了求解最优化问题：
        
        $$
\min _{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)
$$

		样本大时ERM效果很好，但样本容量很小时会发生过拟合现象
    
	- 结构风险最小化（SRM）

		防止过拟合而提出的风险策略，等价于**正则化（regularization）**。表现为在经验风险上添加正则化项（regularizer）或罚项（penalty term）
        
        $$R_{\mathrm{srm}}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)$$
        
        $J(f)$ 代表模型复杂度，**模型 $f$ 越复杂，$J(f)$ 越大**，反之亦然，也就是说复杂度代表了模型的惩罚。$\lambda \geqslant 0$ 是系数，用来权衡经验风险和模型复杂度。
        
- 算法

	- 解析解

	- 数值解 -> 数值优化      

**1.4 模型评估与模型选择**

- 训练误差与测试误差

	测试集上的准确率
$$\begin{align*} r_{test} = \dfrac{1}{N‘} \sum_{i=1}^{N’} I \left( y_{i} = \hat f \left(x_{i} \right) \right) \end{align*} $$
	
    - 其中，$I$是指示函数，即$y = \hat f \left( x \right)$时为1，否则为0。
    
**1.5 模型选择方法**

- 正则化

	正则化项一般为关于模型复杂度的单调递增函数。
    
    正则化的一般形式：
    
    $$\min _{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)$$
    
    - $\lambda \geqslant 0$用于调整经验风险和结构风险的比例

	- 常见的正则化有两种，以平方损失为例：

        - 参数向量的 $L_{1}$ 范数：
          $$
          L(w)=\frac{1}{N} \sum_{i=1}^{N}\left(f\left(x_{i} ; w\right)-y_{i}\right)^{2}+\lambda\|w\|_{1}
          $$

        - 参数向量的 $L_{2}$ 范数:

        $$
        L(w)=\frac{1}{N} \sum_{i=1}^{N}\left(f\left(x_{i} ; w\right)-y_{i}\right)^{2}+\frac{\lambda}{2}\|w\|^{2}
        $$
        
- 交叉验证

	样本数据通常可以分为训练集(training set)，验证集(validation set)和测试集(test set)。
    
    * 简单交叉验证：随机的切分数据为训练集和测试集
	* K 折交叉验证：随机的切分数据为 K 份不相交、大小相同的数据集，留一份做测试，其余的训练，不断重复
	* 留一交叉验证：K 折交叉验证当 K 和数据容量 N 相等时的特殊情况

**1.6 泛化能力**

- 泛化误差上界

	- 性质

		- 样本容量增加，泛化误差上界趋于0
		- 假设空间容量越大，泛化误差上界越大

	- 定理

		**定理：对二分类问题，假设空间是有限个函数 $\mathcal{F}=\left\{f_{1}, f_{2}, \cdots, f_{d}\right\}$ 时，对任意一个函数 $f \in \mathcal{F}$，至少以概率 $ 1 - \delta$，$0<\delta<1$，有以下不等式成立：**
$$
R(f) \leqslant \hat{R}(f)+\varepsilon(d, N, \delta)
$$
**其中，**
$$
\varepsilon(d, N, \delta)=\sqrt{\frac{1}{2 N}\left(\log d+\log \frac{1}{\delta}\right)}
$$
$R(f)$ 表示期望风险，是理论最优值，$\hat{R}(f)$ 表示经验风险，是我们的估计值，$d$ 是假设空间函数个数，$N$ 为样本容量。

    可以看到第二项 $\varepsilon(d, N, \delta)$ 是 $N$ 的单调递减函数，同时也是$\sqrt {\log d}$ 阶的函数

    
**1.8 生成模型与判别模型**

- 生成模型

    生成方法是先学出潜藏的联合概率分布 $P(X,Y)$，然后用条件概率 $P(Y|X)$预测，即给出了由 $X$ 如何生产 $Y$ 的方法。生成方法收敛于真实模型速度快，有隐变量也能用

- 判别模型
    判别方法是直接从数据学条件概率 $P(Y|X)$ 或决策函数 $f(X)$，给出一 个$X$，预测一个 $Y$。判别法直接面向预测，准确率更高

**1.9 评价指标**

以关注的类为正类，其他为负类，对各类预测的情况进行统计，有四种结果：

**TP**：将正类预测为正类的个数

**FN**：将正类预测为负类的个数

**FP**：将负类预测为正类的个数

**TN**：将负类预测为负类的个数

查准率定义为：$P = \frac{T P}{TP + F P}$

召回率定义为：$R = \frac{T P}{TP + FN}$

还有结合了二者，调和平均后的 $F_{1}$ 值：$\frac{2}{F_{1}}=\frac{1}{P}+\frac{1}{R}$，$F_{1} = \frac{2T P}{2TP + FP + FN}$
